{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f77e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2630c22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. \"Cibo Italiano\"\n",
      "2. \"Bella Italia\"\n",
      "3. \"La Dolce Vita\"\n",
      "4. \"Trattoria Elegante\"\n",
      "5. \"Ristorante Di Lusso\"\n",
      "6. \"Cucina Classica\"\n",
      "7. \"Al Dente\"\n",
      "8. \"Fresco Italiano\"\n",
      "9. \"Gusto Italiano\"\n",
      "10. \"Vivace Ristorante\"\n",
      "11. \"Sapori d'Italia\"\n",
      "12. \"Ristorante di Roma\"\n",
      "13. \"Grazie Italiano\"\n",
      "14. \"Sapore di Toscana\"\n",
      "15. \"Bistro Fiore\"\n",
      "16. \"Bella Tavola\"\n",
      "17. \"La Cucina Bella\"\n",
      "18. \"Ristorante Amore\"\n",
      "19. \"Bella Cucina\"\n",
      "20. \"Cucina di Lusso\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature = 0.7)\n",
    "output = llm(\"I want to open an Italian food restuarant, suggest fancy names for this.\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b327864b",
   "metadata": {},
   "source": [
    "### **1.Chain** (Runs a single prompt with a language model. You give it input, it gives you output.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5602ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open an Mexican food restuarant, suggest a fancy name for this.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open an {cuisine} food restuarant, suggest a fancy name for this.\"\n",
    ")\n",
    "\n",
    "prompt_template_name.format(cuisine=\"Mexican\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3db0ee7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Kathiyawadi Delights\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "chain.run(\"Gujarati\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca8eb0f",
   "metadata": {},
   "source": [
    "### **2.Simple Sequential Chain** (Connects multiple chains in a row. The output of one chain becomes the input for the next. It only passes a single string between chains.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3c80561",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature = 0.6)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open an {cuisine} food restuarant, suggest a fancy name for this.\"\n",
    ")\n",
    "name_chain = LLMChain(llm = llm, prompt = prompt_template_name)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['restuarant_name'],\n",
    "    template=\"Suggest some menu items for {restuarant_name}. Return them as a comma seperated list.\"\n",
    ") \n",
    "food_items_chain = LLMChain(llm = llm, prompt = prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae0ee22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Tandoori Chicken\n",
      "2. Vegetable Samosas\n",
      "3. Butter Chicken\n",
      "4. Lamb Rogan Josh\n",
      "5. Palak Paneer\n",
      "6. Chicken Tikka Masala\n",
      "7. Chana Masala\n",
      "8. Garlic Naan\n",
      "9. Mango Lassi\n",
      "10. Biryani Rice\n",
      "11. Aloo Gobi\n",
      "12. Malai Kofta\n",
      "13. Dal Makhani\n",
      "14. Mango Chutney\n",
      "15. Gulab Jamun\n",
      "\n",
      "Tandoori Chicken, Vegetable Samosas, Butter Chicken, Lamb Rogan Josh, Palak Paneer, Chicken Tikka Masala, Chana Masala, Garlic Naan, Mango Lassi, Biryani Rice, Aloo Gobi, Malai Kofta, Dal Makhani, Mango Chutney, Gulab Jamun\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "seq_chain = SimpleSequentialChain(chains = [name_chain, food_items_chain]) # how this works is basically, output of name_chain \n",
    "res = seq_chain.run(\"Indian\")                                              # is taken as the input for food_items_chain\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5614acb4",
   "metadata": {},
   "source": [
    "### **3.Sequential Chain** (Connects multiple chains, but can handle multiple inputs and outputs (using dictionaries). Itâ€™s more flexible and can pass several variables between chains.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40ba61d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature = 0.6)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open an {cuisine} food restuarant, suggest a fancy name for this.\"\n",
    ")\n",
    "name_chain = LLMChain(llm = llm, prompt = prompt_template_name, output_key = \"restuarant_name\")\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['restuarant_name'],\n",
    "    template=\"Suggest some menu items for {restuarant_name}. Return them as a comma seperated list.\"\n",
    ") \n",
    "food_items_chain = LLMChain(llm = llm, prompt = prompt_template_items, output_key = \"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f74393fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fj/kvkr7bks3yx9yvxbxh2hc9hc0000gn/T/ipykernel_72196/1238844908.py:8: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain({'cuisine': 'Indian'}) # need to provide the input varibales as a dict as we might have mutliple inputs in the case of SequentialChain\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Indian',\n",
       " 'restuarant_name': '\\n\\n\"Saffron Spice Palace\"',\n",
       " 'menu_items': '\\n\\n1. Saffron Chicken Tikka Masala\\n2. Lamb Korma\\n3. Vegetable Biryani\\n4. Tandoori Shrimp Skewers\\n5. Paneer Butter Masala\\n6. Dal Makhani\\n7. Chicken Vindaloo\\n8. Aloo Gobi\\n9. Tandoori Naan\\n10. Mango Lassi\\n11. Samosas\\n12. Palak Paneer\\n13. Lamb Rogan Josh\\n14. Chana Masala\\n15. Gulab Jamun dessert.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [name_chain, food_items_chain],\n",
    "    input_variables = ['cuisine'],\n",
    "    output_variables = ['restuarant_name', 'menu_items']\n",
    ")\n",
    "chain({'cuisine': 'Indian'}) # need to provide the input varibales as a dict as we might have mutliple inputs in the case of SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e46fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
